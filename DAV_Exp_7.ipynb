{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xq7lFU1wMia"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment - 7: Perform the steps involved in Text Analytics in Python & R\n",
        "\n",
        "**LabOutcomes (LO):\n",
        "Design Text Analytics Application on a given data set. (LO4) **\n"
      ],
      "metadata": {
        "id": "elkJVsjbwQr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**\n"
      ],
      "metadata": {
        "id": "-h4cK0_gw2_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63qjCLz0yfMu",
        "outputId": "26ae7d02-39e8-4988-bdd3-fe1293786871"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVXh1Hktx_D4",
        "outputId": "2056f7b4-4944-4e59-cb66-15ba4241ba6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample text\n",
        "text = \"Tokenization is the process of breaking down text into smaller units called tokens.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Print the tokens\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7mzYIZBxFCl",
        "outputId": "99d5f9cc-70a4-4e76-af24-9e073a988ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'down', 'text', 'into', 'smaller', 'units', 'called', 'tokens', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency Distribution"
      ],
      "metadata": {
        "id": "_3Na2TEDywND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n"
      ],
      "metadata": {
        "id": "CtUvVx2kzB3u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dist = FreqDist(tokens)\n",
        "\n",
        "# Print the frequency distribution\n",
        "print(freq_dist.most_common())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN3ce0ZlzC5d",
        "outputId": "eaf69457-9e17-4397-d6b0-b82f1532c8b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Tokenization', 1), ('is', 1), ('the', 1), ('process', 1), ('of', 1), ('breaking', 1), ('down', 1), ('text', 1), ('into', 1), ('smaller', 1), ('units', 1), ('called', 1), ('tokens', 1), ('.', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymp6OG4hzC_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove stopwords & punctuations**"
      ],
      "metadata": {
        "id": "DRGvS8Qi0Mll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SENvFh40RqR",
        "outputId": "88e541eb-34c9-4548-b1ae-987e34482122"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Tokenization is the process of breaking down text into smaller units called tokens,It is important in natural language processing.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Remove punctuation\n",
        "filtered_tokens = [word for word in filtered_tokens if word not in string.punctuation]\n",
        "\n",
        "# Print filtered tokens\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMOICW5l0Xck",
        "outputId": "ba9eb88d-3761-4452-c704-03e784ced40a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenization', 'process', 'breaking', 'text', 'smaller', 'units', 'called', 'tokens', 'important', 'natural', 'language', 'processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lexicon Normalization (Stemming, Lemmatization)**"
      ],
      "metadata": {
        "id": "7fnqsPlX07H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"running runner runs\"\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(word) for word in tokens]\n",
        "print(stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjaEIrS50XiY",
        "outputId": "e8d49552-aa46-4bd5-96b1-c5d63af124dc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'runner', 'run']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download WordNet corpus if not already downloaded\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Input text\n",
        "text = \"The cats are running and jumping on the beds.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Initialize WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize each token\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "# Print the lemmatized tokens\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO6JTEgm3CID",
        "outputId": "cf11022d-0be5-45e6-85db-7d4b481dad94"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'cat', 'are', 'running', 'and', 'jumping', 'on', 'the', 'bed', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part of Speech tagging**"
      ],
      "metadata": {
        "id": "LdiMfra43RBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Print POS tagged tokens\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K-6c20Z3Xpk",
        "outputId": "f5e0ccd6-37bc-4311-8271-1b7955e5d556"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('cats', 'NNS'), ('are', 'VBP'), ('running', 'VBG'), ('and', 'CC'), ('jumping', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('beds', 'NNS'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHHOm60J372e",
        "outputId": "24646546-97c6-4b63-a99e-4134c9ad09f1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognization**"
      ],
      "metadata": {
        "id": "SEx_o-1-4A-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JnsAe-op4Hjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flrE0SiK4dL8",
        "outputId": "13be8b22-bdd2-49e4-bf47-4b0276f0e952"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wCjVFso65O-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O0SE92H65PE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample text\n",
        "text = \"Apple is headquartered in Cupertino, California.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Perform Named Entity Recognition\n",
        "ne_tags = nltk.pos_tag(tokens)\n",
        "ne_chunks = nltk.ne_chunk(ne_tags)\n",
        "\n",
        "# Print Named Entities\n",
        "for chunk in ne_chunks:\n",
        "    if hasattr(chunk, 'label'):\n",
        "        print(chunk.label(), ' '.join(c[0] for c in chunk))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkT459kI5HHO",
        "outputId": "6d24e0ca-5881-4f68-ce71-9dcc448792cd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPE Apple\n",
            "GPE Cupertino\n",
            "GPE California\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scrape data from a website**"
      ],
      "metadata": {
        "id": "JLGOCeIs5QMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the website to scrape\n",
        "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content of the webpage\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find and extract the desired data from the webpage\n",
        "    # For example, if you want to scrape all the links on the webpage:\n",
        "    links = soup.find_all('a')\n",
        "\n",
        "    # Print the extracted links\n",
        "    for link in links:\n",
        "        print(link.get('href'))\n",
        "else:\n",
        "    print('Failed to retrieve the webpage. Status code:', response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jobIdApI5S4x",
        "outputId": "8aa8e175-ac6d-4196-85a8-ba6a48b0269c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#bodyContent\n",
            "/wiki/Main_Page\n",
            "/wiki/Wikipedia:Contents\n",
            "/wiki/Portal:Current_events\n",
            "/wiki/Special:Random\n",
            "/wiki/Wikipedia:About\n",
            "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
            "/wiki/Help:Contents\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Wikipedia:Community_portal\n",
            "/wiki/Special:RecentChanges\n",
            "/wiki/Wikipedia:File_upload_wizard\n",
            "/wiki/Main_Page\n",
            "/wiki/Special:Search\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Main+Page\n",
            "/w/index.php?title=Special:UserLogin&returnto=Main+Page\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Main+Page\n",
            "/w/index.php?title=Special:UserLogin&returnto=Main+Page\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Special:MyContributions\n",
            "/wiki/Special:MyTalk\n",
            "/wiki/Main_Page\n",
            "/wiki/Talk:Main_Page\n",
            "/wiki/Main_Page\n",
            "/w/index.php?title=Main_Page&action=edit\n",
            "/w/index.php?title=Main_Page&action=history\n",
            "/wiki/Main_Page\n",
            "/w/index.php?title=Main_Page&action=edit\n",
            "/w/index.php?title=Main_Page&action=history\n",
            "/wiki/Special:WhatLinksHere/Main_Page\n",
            "/wiki/Special:RecentChangesLinked/Main_Page\n",
            "/wiki/Wikipedia:File_Upload_Wizard\n",
            "/wiki/Special:SpecialPages\n",
            "/w/index.php?title=Main_Page&oldid=1189617895\n",
            "/w/index.php?title=Main_Page&action=info\n",
            "/w/index.php?title=Special:CiteThisPage&page=Main_Page&id=1189617895&wpFormIdentifier=titleform\n",
            "/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMain_Page\n",
            "/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMain_Page\n",
            "https://www.wikidata.org/wiki/Special:EntityPage/Q5296\n",
            "/w/index.php?title=Special:DownloadAsPdf&page=Main_Page&action=show-download-screen\n",
            "/w/index.php?title=Main_Page&printable=yes\n",
            "https://commons.wikimedia.org/wiki/Main_Page\n",
            "https://foundation.wikimedia.org/wiki/Home\n",
            "https://www.mediawiki.org/wiki/MediaWiki\n",
            "https://meta.wikimedia.org/wiki/Main_Page\n",
            "https://outreach.wikimedia.org/wiki/Main_Page\n",
            "https://wikisource.org/wiki/Main_Page\n",
            "https://species.wikimedia.org/wiki/Main_Page\n",
            "https://en.wikibooks.org/wiki/Main_Page\n",
            "https://www.wikidata.org/wiki/Wikidata:Main_Page\n",
            "https://www.wikifunctions.org/wiki/Wikifunctions:Main_Page\n",
            "https://wikimania.wikimedia.org/wiki/Wikimania\n",
            "https://en.wikinews.org/wiki/Main_Page\n",
            "https://en.wikiquote.org/wiki/Main_Page\n",
            "https://en.wikisource.org/wiki/Main_Page\n",
            "https://en.wikiversity.org/wiki/Wikiversity:Main_Page\n",
            "https://en.wikivoyage.org/wiki/Main_Page\n",
            "https://en.wiktionary.org/wiki/Wiktionary:Main_Page\n",
            "/wiki/Wikipedia\n",
            "/wiki/Free_content\n",
            "/wiki/Encyclopedia\n",
            "/wiki/Help:Introduction_to_Wikipedia\n",
            "/wiki/Special:Statistics\n",
            "/wiki/English_language\n",
            "/wiki/File:Caf_hardman.jpg\n",
            "/wiki/Donald_Hardman\n",
            "/wiki/Royal_Air_Force\n",
            "/wiki/Royal_Flying_Corps\n",
            "/wiki/Fighter_aircraft\n",
            "/wiki/Western_Front_(World_War_I)\n",
            "/wiki/Flying_ace\n",
            "/wiki/Wing_commander\n",
            "/wiki/Air_Ministry\n",
            "/wiki/Burma_campaign\n",
            "/wiki/RAF_Staff_College,_Bracknell\n",
            "/wiki/RAF_Home_Command\n",
            "/wiki/Knight\n",
            "/wiki/Chief_of_Air_Force_(Australia)\n",
            "/wiki/Royal_Australian_Air_Force\n",
            "/wiki/RAAF_area_commands\n",
            "/wiki/Air_Council\n",
            "/wiki/Air_chief_marshal\n",
            "/wiki/Donald_Hardman\n",
            "/wiki/Quarter_sovereign\n",
            "/wiki/Teloschistaceae\n",
            "/wiki/John_Spencer_(snooker_player)\n",
            "/wiki/Wikipedia:Today%27s_featured_article/February_2024\n",
            "https://lists.wikimedia.org/postorius/lists/daily-article-l.lists.wikimedia.org/\n",
            "/wiki/Wikipedia:Featured_articles\n",
            "/wiki/Wikipedia:About_Today%27s_featured_article\n",
            "/wiki/File:20210902_Sacred_Heart_Cathedral_of_Kaifeng_01.jpg\n",
            "/wiki/Sacred_Heart_Cathedral,_Kaifeng\n",
            "/wiki/Kaifeng\n",
            "/wiki/Chinese_Civil_War\n",
            "/wiki/Max_Stephan\n",
            "/wiki/1892_Biddle_vs._Livingstone_football_game\n",
            "/wiki/Historically_black_colleges_and_universities\n",
            "/wiki/Lewis_Pragasam\n",
            "/wiki/Joy_to_the_World\n",
            "/wiki/Myocardial_infarction\n",
            "/wiki/Peter_Parker_(Marvel_Cinematic_Universe)\n",
            "/wiki/Avengers:_Endgame\n",
            "/wiki/Avengers_assemble_scene\n",
            "/wiki/Anthony_W._Case\n",
            "/wiki/1998_Thurston_High_School_shooting\n",
            "/wiki/Astrophysics\n",
            "/wiki/Taylor_Swift\n",
            "/wiki/The_Tortured_Poets_Department\n",
            "/wiki/Grammy_Award_for_Best_Pop_Vocal_Album\n",
            "/wiki/Midnights\n",
            "/wiki/Delulu\n",
            "/wiki/Wikipedia:Recent_additions\n",
            "/wiki/Help:Your_first_article\n",
            "/wiki/Template_talk:Did_you_know\n",
            "/wiki/File:Cillian_Murphy_at_Berlinale_2024,_Ausschnitt.jpg\n",
            "/wiki/77th_British_Academy_Film_Awards\n",
            "/wiki/Oppenheimer_(film)\n",
            "/wiki/BAFTA_Award_for_Best_Film\n",
            "/wiki/BAFTA_Award_for_Best_Actor_in_a_Leading_Role\n",
            "/wiki/Cillian_Murphy\n",
            "/wiki/Alexei_Navalny\n",
            "/wiki/Death_of_Alexei_Navalny\n",
            "/wiki/Corrective_labor_colony\n",
            "/wiki/Kharp\n",
            "/wiki/American_football\n",
            "/wiki/Kansas_City_Chiefs\n",
            "/wiki/San_Francisco_49ers\n",
            "/wiki/Super_Bowl_LVIII\n",
            "/wiki/Association_football\n",
            "/wiki/2023_Africa_Cup_of_Nations\n",
            "/wiki/Ivory_Coast_national_football_team\n",
            "/wiki/Nigeria_national_football_team\n",
            "/wiki/2023_Africa_Cup_of_Nations_final\n",
            "/wiki/Alexander_Stubb\n",
            "/wiki/2024_Finnish_presidential_election\n",
            "/wiki/President_of_Finland\n",
            "/wiki/Portal:Current_events\n",
            "/wiki/Israel%E2%80%93Hamas_war\n",
            "/wiki/Myanmar_civil_war_(2021%E2%80%93present)\n",
            "/wiki/Red_Sea_crisis\n",
            "/wiki/Russian_invasion_of_Ukraine\n",
            "/wiki/Timeline_of_the_Russian_invasion_of_Ukraine_(1_December_2023_%E2%80%93_present)\n",
            "/wiki/Deaths_in_2024\n",
            "/wiki/Gamini_Jayawickrama_Perera\n",
            "/wiki/Mike_Procter\n",
            "/wiki/Bryan_Thomas_(architect)\n",
            "/wiki/William_Post_(businessman)\n",
            "/wiki/Chuck_Mawhinney\n",
            "/wiki/Rudolf_Jansen\n",
            "/wiki/Wikipedia:In_the_news/Candidates\n",
            "/wiki/February_21\n",
            "/wiki/File:Malcolm-x.jpg\n",
            "/wiki/1746\n",
            "/wiki/Jacobite_rising_of_1745\n",
            "/wiki/Siege_of_Inverness_(1746)\n",
            "/wiki/1862\n",
            "/wiki/American_Civil_War\n",
            "/wiki/Confederate_States_Army\n",
            "/wiki/New_Mexico_campaign\n",
            "/wiki/Battle_of_Valverde\n",
            "/wiki/1952\n",
            "/wiki/Bengali_language_movement\n",
            "/wiki/Bengali_language\n",
            "/wiki/Dhaka\n",
            "/wiki/1965\n",
            "/wiki/Black_nationalism\n",
            "/wiki/Malcolm_X\n",
            "/wiki/Audubon_Ballroom\n",
            "/wiki/1973\n",
            "/wiki/Libyan_Arab_Airlines_Flight_114\n",
            "/wiki/Fighter_aircraft\n",
            "/wiki/Gaius_Caesar\n",
            "/wiki/L%C3%A9o_Delibes\n",
            "/wiki/Incas_(parakeet)\n",
            "/wiki/Elliot_Page\n",
            "/wiki/February_20\n",
            "/wiki/February_21\n",
            "/wiki/February_22\n",
            "/wiki/Wikipedia:Selected_anniversaries/February\n",
            "https://lists.wikimedia.org/postorius/lists/daily-article-l.lists.wikimedia.org/\n",
            "/wiki/List_of_days_of_the_year\n",
            "/wiki/File:Mudh_Towering_Range_Pin_Spiti_Himachal_Jun18_D72_7095.jpg\n",
            "/wiki/Mud_(village)\n",
            "/wiki/Spiti\n",
            "/wiki/Himachal_Pradesh\n",
            "/wiki/Arenite\n",
            "/wiki/User:Tagooty\n",
            "/wiki/Template:POTD/2024-02-20\n",
            "/wiki/Template:POTD/2024-02-19\n",
            "/wiki/Template:POTD/2024-02-18\n",
            "/wiki/Wikipedia:Picture_of_the_day/Archive\n",
            "/wiki/Wikipedia:Featured_pictures\n",
            "/wiki/Wikipedia:Community_portal\n",
            "/wiki/Wikipedia:Village_pump\n",
            "/wiki/Wikipedia:News\n",
            "/wiki/Wikipedia:Teahouse\n",
            "/wiki/Wikipedia:Help_desk\n",
            "/wiki/Wikipedia:Reference_desk\n",
            "/wiki/Wikipedia:Contents/Portals\n",
            "/wiki/Wikimedia_Foundation\n",
            "https://wikimediafoundation.org/our-work/wikimedia-projects/\n",
            "https://commons.wikimedia.org/wiki/\n",
            "https://commons.wikimedia.org/wiki/\n",
            "https://www.mediawiki.org/wiki/\n",
            "https://www.mediawiki.org/wiki/\n",
            "https://meta.wikimedia.org/wiki/\n",
            "https://meta.wikimedia.org/wiki/\n",
            "https://en.wikibooks.org/wiki/\n",
            "https://en.wikibooks.org/wiki/\n",
            "https://www.wikidata.org/wiki/\n",
            "https://www.wikidata.org/wiki/\n",
            "https://en.wikinews.org/wiki/\n",
            "https://en.wikinews.org/wiki/\n",
            "https://en.wikiquote.org/wiki/\n",
            "https://en.wikiquote.org/wiki/\n",
            "https://en.wikisource.org/wiki/\n",
            "https://en.wikisource.org/wiki/\n",
            "https://species.wikimedia.org/wiki/\n",
            "https://species.wikimedia.org/wiki/\n",
            "https://en.wikiversity.org/wiki/\n",
            "https://en.wikiversity.org/wiki/\n",
            "https://en.wikivoyage.org/wiki/\n",
            "https://en.wikivoyage.org/wiki/\n",
            "https://en.wiktionary.org/wiki/\n",
            "https://en.wiktionary.org/wiki/\n",
            "/wiki/English_language\n",
            "https://meta.wikimedia.org/wiki/List_of_Wikipedias\n",
            "https://ar.wikipedia.org/wiki/\n",
            "https://arz.wikipedia.org/wiki/\n",
            "https://de.wikipedia.org/wiki/\n",
            "https://es.wikipedia.org/wiki/\n",
            "https://fr.wikipedia.org/wiki/\n",
            "https://it.wikipedia.org/wiki/\n",
            "https://nl.wikipedia.org/wiki/\n",
            "https://ja.wikipedia.org/wiki/\n",
            "https://pl.wikipedia.org/wiki/\n",
            "https://pt.wikipedia.org/wiki/\n",
            "https://ru.wikipedia.org/wiki/\n",
            "https://sv.wikipedia.org/wiki/\n",
            "https://uk.wikipedia.org/wiki/\n",
            "https://vi.wikipedia.org/wiki/\n",
            "https://zh.wikipedia.org/wiki/\n",
            "https://id.wikipedia.org/wiki/\n",
            "https://ms.wikipedia.org/wiki/\n",
            "https://zh-min-nan.wikipedia.org/wiki/\n",
            "https://bg.wikipedia.org/wiki/\n",
            "https://ca.wikipedia.org/wiki/\n",
            "https://cs.wikipedia.org/wiki/\n",
            "https://da.wikipedia.org/wiki/\n",
            "https://eo.wikipedia.org/wiki/\n",
            "https://eu.wikipedia.org/wiki/\n",
            "https://fa.wikipedia.org/wiki/\n",
            "https://he.wikipedia.org/wiki/\n",
            "https://hy.wikipedia.org/wiki/\n",
            "https://ko.wikipedia.org/wiki/\n",
            "https://hu.wikipedia.org/wiki/\n",
            "https://no.wikipedia.org/wiki/\n",
            "https://ro.wikipedia.org/wiki/\n",
            "https://sr.wikipedia.org/wiki/\n",
            "https://sh.wikipedia.org/wiki/\n",
            "https://fi.wikipedia.org/wiki/\n",
            "https://tr.wikipedia.org/wiki/\n",
            "https://ast.wikipedia.org/wiki/\n",
            "https://bn.wikipedia.org/wiki/\n",
            "https://bs.wikipedia.org/wiki/\n",
            "https://ckb.wikipedia.org/wiki/\n",
            "https://et.wikipedia.org/wiki/\n",
            "https://el.wikipedia.org/wiki/\n",
            "https://simple.wikipedia.org/wiki/\n",
            "https://fy.wikipedia.org/wiki/\n",
            "https://ga.wikipedia.org/wiki/\n",
            "https://gl.wikipedia.org/wiki/\n",
            "https://hr.wikipedia.org/wiki/\n",
            "https://ka.wikipedia.org/wiki/\n",
            "https://ku.wikipedia.org/wiki/\n",
            "https://lv.wikipedia.org/wiki/\n",
            "https://lt.wikipedia.org/wiki/\n",
            "https://ml.wikipedia.org/wiki/\n",
            "https://mk.wikipedia.org/wiki/\n",
            "https://nn.wikipedia.org/wiki/\n",
            "https://pa.wikipedia.org/wiki/\n",
            "https://sq.wikipedia.org/wiki/\n",
            "https://sk.wikipedia.org/wiki/\n",
            "https://sl.wikipedia.org/wiki/\n",
            "https://th.wikipedia.org/wiki/\n",
            "https://te.wikipedia.org/wiki/\n",
            "https://ur.wikipedia.org/wiki/\n",
            "https://uz.wikipedia.org/wiki/\n",
            "https://en.wikipedia.org/w/index.php?title=Main_Page&oldid=1189617895\n",
            "https://ar.wikipedia.org/wiki/\n",
            "https://bn.wikipedia.org/wiki/\n",
            "https://bg.wikipedia.org/wiki/\n",
            "https://bs.wikipedia.org/wiki/\n",
            "https://ca.wikipedia.org/wiki/\n",
            "https://cs.wikipedia.org/wiki/\n",
            "https://da.wikipedia.org/wiki/\n",
            "https://de.wikipedia.org/wiki/\n",
            "https://et.wikipedia.org/wiki/\n",
            "https://el.wikipedia.org/wiki/\n",
            "https://es.wikipedia.org/wiki/\n",
            "https://eo.wikipedia.org/wiki/\n",
            "https://eu.wikipedia.org/wiki/\n",
            "https://fa.wikipedia.org/wiki/\n",
            "https://fr.wikipedia.org/wiki/\n",
            "https://gl.wikipedia.org/wiki/\n",
            "https://ko.wikipedia.org/wiki/\n",
            "https://hr.wikipedia.org/wiki/\n",
            "https://id.wikipedia.org/wiki/\n",
            "https://it.wikipedia.org/wiki/\n",
            "https://he.wikipedia.org/wiki/\n",
            "https://ka.wikipedia.org/wiki/\n",
            "https://lv.wikipedia.org/wiki/\n",
            "https://lt.wikipedia.org/wiki/\n",
            "https://hu.wikipedia.org/wiki/\n",
            "https://mk.wikipedia.org/wiki/\n",
            "https://ms.wikipedia.org/wiki/\n",
            "https://nl.wikipedia.org/wiki/\n",
            "https://ja.wikipedia.org/wiki/\n",
            "https://no.wikipedia.org/wiki/\n",
            "https://nn.wikipedia.org/wiki/\n",
            "https://pl.wikipedia.org/wiki/\n",
            "https://pt.wikipedia.org/wiki/\n",
            "https://ro.wikipedia.org/wiki/\n",
            "https://ru.wikipedia.org/wiki/\n",
            "https://simple.wikipedia.org/wiki/\n",
            "https://sk.wikipedia.org/wiki/\n",
            "https://sl.wikipedia.org/wiki/\n",
            "https://ckb.wikipedia.org/wiki/\n",
            "https://sr.wikipedia.org/wiki/\n",
            "https://sh.wikipedia.org/wiki/\n",
            "https://fi.wikipedia.org/wiki/\n",
            "https://sv.wikipedia.org/wiki/\n",
            "https://th.wikipedia.org/wiki/\n",
            "https://tr.wikipedia.org/wiki/\n",
            "https://uk.wikipedia.org/wiki/\n",
            "https://vi.wikipedia.org/wiki/\n",
            "https://zh.wikipedia.org/wiki/\n",
            "//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\n",
            "//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\n",
            "//foundation.wikimedia.org/wiki/Terms_of_Use\n",
            "//foundation.wikimedia.org/wiki/Privacy_policy\n",
            "//www.wikimediafoundation.org/\n",
            "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\n",
            "/wiki/Wikipedia:About\n",
            "/wiki/Wikipedia:General_disclaimer\n",
            "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\n",
            "https://developer.wikimedia.org\n",
            "https://stats.wikimedia.org/#/en.wikipedia.org\n",
            "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement\n",
            "//en.m.wikipedia.org/w/index.php?title=Main_Page&mobileaction=toggle_view_mobile\n",
            "https://wikimediafoundation.org/\n",
            "https://www.mediawiki.org/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion: We have successfully perormed text analysis."
      ],
      "metadata": {
        "id": "5g-tGEOU6Bhu"
      }
    }
  ]
}